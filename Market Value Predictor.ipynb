{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Market Value Predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessarry libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Library that allows data manipulation and analysis\n",
    "import numpy as np  # Library for high-level mathematical functions and support for multi-dimensional arrays\n",
    "import matplotlib.pyplot as plt  # Library for plotting\n",
    "import seaborn as sns  # Additional Library for plotting\n",
    "\n",
    "# To import the necessarry libraries and dependendencies required for the machine learning models and their respective training and evaluation.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "\n",
    "# To import metrics to measure performance\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option(\"display.max_rows\", None)  # To better display the rows when there are too many\n",
    "pd.set_option(\"display.max_columns\", None)  # To better display the columns when there are too many\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/aleja/OneDrive/Desktop/Data Analytics Msc/Thesis/male_players.csv\") #Loading the CSV file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking general information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True,show_counts=True) # For a summarry of the columns available, the amount of nulls per column and the data type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This initial glimpse of the code allows us to make quick inferences about the dataset being handled. We are dealing with 111 initial columns in our dataset which already shows us that we are probably going to need to perform data cleaning to get rid of unnecesarry columns.\n",
    "\n",
    "- The Non-Null Count also signals that we must perform data cleaning as the count value are not the same for all columns.\n",
    "\n",
    "- Lastly, the Data type of each column tells us how we are going to have to handle each column at the moment of making operations and when considering the steps to handle the different types of variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We run the following method to get a initial look at the data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This overview of the dataset allows us to understand our next steps for data preprocessing: \n",
    "1. Player positions contain multiple positions separated by a comma. We will have to reduce it to only one so that comparisons can be made properly by avoiding having a mix of multiple positions being recognized as their own category. (This step was completed in Excel using the LEFT and FIND functions, for the sake of including various data analysis tools; hence the player_positions_2 colum).\n",
    "1. Some of the scores assigned to each player for each position in the field (ls,st,rs,lw, etc.) include an operation, i.e. 90+3, which was included to include potential based on certain conditions. This causes the data type to be an object when it would be needed for these colums to be an integer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that will allow us to perform the operations found in some of player position rating columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate the effective overall rating for the player position rankings\n",
    "# Define a function to handle both addition and subtraction\n",
    "def calculate_operation(x):\n",
    "    x = str(x)  # Convert to string to avoid the error\n",
    "    if '+' in x:\n",
    "        return sum(map(int, x.split('+')))\n",
    "    elif '-' in x:\n",
    "        parts = x.split('-')\n",
    "        return int(parts[0]) - int(parts[1])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "# Apply the function to multiple columns\n",
    "columns_to_process = ['ls', 'st', 'rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk']          \n",
    "\n",
    "# Apply the function to the specified columns and update the DataFrame\n",
    "for col in columns_to_process:\n",
    "    if col in df.columns:  # Check if the column exists in the DataFrame\n",
    "        df[col] = df[col].apply(calculate_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invert the values of ordinal variables like league level so that the logic for all cardinal variable stays consistent; higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['league_level'] = 6 - df['league_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the dataset we see that there is a 'player_id' column that holds a unique identifier for each player. We use the following lines of code to check on duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(subset=['player_id' ], keep=False)] #To check if there are any duplicates for player id\n",
    "duplicates = duplicates.sort_values(by=['player_id']) #To sort and show the duplicated together in case there are any\n",
    "duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to handle missing values as they will skew our results and ML algorithms dont function properly with them. We first analyze the missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum() #To count the sum of the null values in our dataset\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are columns that have a high percentage of missing values, upwards of 90% in some cases. We decided the best course of action is to get rid of those columns all together and also drop some columns that dont provide valuable information at a first glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop columns that have high null value count and that dont provide much information\n",
    "df = df.drop(columns=['nation_jersey_number','player_traits' , 'goalkeeping_speed',\n",
    "                       'club_loaned_from', 'nation_team_id', 'nation_position',\n",
    "                       'player_tags', 'fifa_update', 'nationality_id', 'real_face',\n",
    "                       'league_id','club_team_id','club_joined_date','update_as_of',\n",
    "                       'dob', 'player_positions', 'body_type'\n",
    "                       ]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the market value is our target variable, it is in our best interest to drop those records that have a null value in this column. We also drop those players that don't have a club position as it is basic for the types of players that we want to analyze.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To drop the rows of players missing their market value \n",
    "df = df.dropna(subset=['value_eur'])\n",
    "\n",
    "#To drop the rows of players missing information\n",
    "df = df.dropna(subset=['club_position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have solved the null values that could be disposed off, we must analyze what procedure to take to solve the null values in the columns that will prove useful to us. We will use histograms to check on the distribution for each of the variables and analyze the best method to impute said columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.hist(figsize = (25,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histograms gave us interesting insights of our data. \n",
    "- The distributions for 'value_eur' and 'wage_eur' present a high degree of skewness to the left, which might affect our data. We will need to apply some transformation to correct this.\n",
    "- The columns 'pace','shooting','passing','dribbling','mentality_composure' all present a normal distribution, which means that null values can be imputed using the mean.\n",
    "- The columns 'defending','physic','release_clause_eur' present skewness in their distributions, meaning that null values can be imputed using the median.\n",
    "- Colums with categorical variables that present null values like 'league_level' can be imputed using the mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To impute the columns that have a normal distribution with the mean\n",
    "df['pace'].fillna(df['pace'].mean(), inplace=True)\n",
    "df['shooting'].fillna(df['shooting'].mean(), inplace=True)\n",
    "df['passing'].fillna(df['passing'].mean(), inplace=True)\n",
    "df['dribbling'].fillna(df['dribbling'].mean(), inplace=True)\n",
    "df['mentality_composure'].fillna(df['mentality_composure'].mean(), inplace=True)\n",
    "\n",
    "#To impute the colums that present skewness with the median\n",
    "df['defending'].fillna(df['defending'].median(), inplace=True)\n",
    "df['physic'].fillna(df['physic'].median(), inplace=True)\n",
    "df['release_clause_eur'].fillna(df['release_clause_eur'].median(), inplace=True)\n",
    "\n",
    "#To impute the values of a ordinal variable with the mode\n",
    "df['league_level'] = df['league_level'].fillna(df['league_level'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the sum of the null counts to verify that are not any left. ('player_face_url' still presents null values but that is a column that will not be used in the analysis and is only needed for the construction of the Tableau Dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum() #To count the sum of the null values in our dataset\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a look a the histograms for each variable we could realize that we would need to apply data transformations techniques that would help us reduce the imbalance in our dataset. The histograms already give us a hint at potential outliers, however we use box plots to confirm take a much more precise look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.plot(kind='box', figsize=(25, 25), subplots=True, layout=(10, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple conclusions that we can draw from examining the box plots\n",
    "- Some of the variables present a lot of outliers but in some of them it actually makes sense, i.e. height can present outliers on both ends of the box as goalkeepers are usually tall and some regions of the world have shorter players; not necessarily being determinant of player value. This teaches us that we must focus our outlier removal efforts in variables where outliers dont make sense or could potentially affect our results. \n",
    "- Other variables like the goalkeeping score present many outliers as it is logical that field players have low scores in this regard.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a log transformation for some of the columns in our dataset that we previously recognized that had heavy skewness to one side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_eur'] = np.log1p(df['value_eur'])\n",
    "df['wage_eur'] = np.log1p(df['wage_eur'])\n",
    "df['release_clause_eur'] = np.log1p(df['release_clause_eur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data inmbalance has been handled, it is advisable to put most of the numeric variables on similar scales so that they are more easily comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['value_eur','wage_eur','release_clause_eur', 'overall','potential',\n",
    "                    'height_cm','weight_kg','pace',\n",
    "                    'shooting','passing','dribbling','defending','physic',\n",
    "                    'attacking_crossing','attacking_finishing','attacking_heading_accuracy',\n",
    "                    'attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve',\n",
    "                    'skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration',\n",
    "                    'movement_sprint_speed','movement_agility','movement_reactions','movement_balance',\n",
    "                    'power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots',\n",
    "                    'mentality_aggression','mentality_interceptions','mentality_positioning',\n",
    "                    'mentality_vision','mentality_penalties','mentality_composure','defending_marking_awareness',\n",
    "                    'defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving',\n",
    "                    'goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning',\n",
    "                    'goalkeeping_reflexes','ls', 'st', 'rs','lw','lf','cf','rf','rw','lam',\n",
    "                    'cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb',\n",
    "                    'lcb','cb','rcb','rb','gk']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "df[columns_to_scale] = pd.DataFrame(scaled_data, index=df.index, columns=columns_to_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables have to be encoded for a better performance with our ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply a Hot Encoder to the categorical variables that are not ordinal\n",
    "columns_to_encode = ['player_positions_2','preferred_foot','work_rate','body_type_2']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None) \n",
    "encoded_data = encoder.fit_transform(df[columns_to_encode])\n",
    "encoded_columns = encoder.get_feature_names_out(columns_to_encode)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns, index=df.index)\n",
    "df = pd.concat([df.drop(columns=columns_to_encode), encoded_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since keeping the interpretability of our data is of high importance and we want to focus on the relationships between our covariables and our target variables, we decided that the best option for dimensionality reduction would be to use embedded feature selection methods. These methods are more efficient as they perform the feature selection as part of the model building process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['player_id', 'player_url','short_name','long_name','player_face_url','club_name','league_name','club_position','nationality_name']  # We exclude columns that are not necessary in the analysis and that contain strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['value_eur'] + exclude_columns)  # Features\n",
    "y = df['value_eur']  # Target\n",
    "\n",
    "# Split data into train and test based on 'fifa_version'\n",
    "X_train = X[df['fifa_version'] == 22]\n",
    "X_test = X[df['fifa_version'] == 23]\n",
    "y_train = y[df['fifa_version'] == 22]\n",
    "y_test = y[df['fifa_version'] == 23]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Hyperparameters: {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "MAE: 2283251.333605772\n",
      "MSE: 23529832688316.625\n",
      "RMSE: 4850755.888345302\n",
      "MAPE: 401.5849049968213\n",
      "R2 Score: 0.5922950123725974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Elastic Net model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 1]  # Mixing parameter (0 = Ridge, 1 = Lasso)\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision Tree model\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 50],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for splits\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 150, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for splits\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "# To print which were the most important features selected by the algorithm\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", importance_df.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "MAE: 316264.60150542925\n",
      "MSE: 829730676339.1951\n",
      "RMSE: 910895.5353602272\n",
      "MAPE: 24.51655404553121\n",
      "R2 Score: 0.985623130448398\n",
      "Feature Importances:\n",
      "                             Feature  Importance\n",
      "13               release_clause_eur    0.155642\n",
      "2                         potential    0.136842\n",
      "33               movement_reactions    0.121989\n",
      "62                              lam    0.085333\n",
      "58                               lf    0.072880\n",
      "1                           overall    0.051657\n",
      "63                              cam    0.050046\n",
      "69                               rm    0.034277\n",
      "59                               cf    0.034102\n",
      "64                              ram    0.027315\n",
      "60                               rf    0.024538\n",
      "71                              ldm    0.023758\n",
      "65                               lm    0.019007\n",
      "57                               lw    0.014954\n",
      "4                               age    0.014130\n",
      "3                          wage_eur    0.012302\n",
      "77                               cb    0.011199\n",
      "110              body_type_2_Unique    0.010589\n",
      "12         international_reputation    0.010341\n",
      "75                               lb    0.009919\n",
      "67                               cm    0.009774\n",
      "53             goalkeeping_reflexes    0.008360\n",
      "66                              lcm    0.007565\n",
      "78                              rcb    0.005375\n",
      "54                               ls    0.005309\n",
      "80                               gk    0.004753\n",
      "73                              rdm    0.003784\n",
      "56                               rs    0.002846\n",
      "72                              cdm    0.002794\n",
      "23          attacking_short_passing    0.002313\n",
      "68                              rcm    0.002100\n",
      "76                              lcb    0.001402\n",
      "47        defending_standing_tackle    0.001338\n",
      "17                        dribbling    0.001337\n",
      "46      defending_marking_awareness    0.001261\n",
      "18                        defending    0.001020\n",
      "14                             pace    0.001015\n",
      "37                    power_stamina    0.000984\n",
      "9    club_contract_valid_until_year    0.000954\n",
      "79                               rb    0.000918\n",
      "38                   power_strength    0.000912\n",
      "22       attacking_heading_accuracy    0.000909\n",
      "70                              lwb    0.000892\n",
      "55                               st    0.000842\n",
      "15                         shooting    0.000759\n",
      "31            movement_sprint_speed    0.000753\n",
      "45              mentality_composure    0.000729\n",
      "30            movement_acceleration    0.000720\n",
      "49               goalkeeping_diving    0.000719\n",
      "29               skill_ball_control    0.000714\n",
      "20               attacking_crossing    0.000549\n",
      "52          goalkeeping_positioning    0.000469\n",
      "21              attacking_finishing    0.000443\n",
      "74                              rwb    0.000390\n",
      "16                          passing    0.000367\n",
      "48         defending_sliding_tackle    0.000326\n",
      "43                 mentality_vision    0.000303\n",
      "27                skill_fk_accuracy    0.000279\n",
      "61                               rw    0.000278\n",
      "25                  skill_dribbling    0.000263\n",
      "39                 power_long_shots    0.000258\n",
      "40             mentality_aggression    0.000240\n",
      "24                attacking_volleys    0.000204\n",
      "50             goalkeeping_handling    0.000198\n",
      "35                 power_shot_power    0.000187\n",
      "41          mentality_interceptions    0.000172\n",
      "44              mentality_penalties    0.000144\n",
      "28               skill_long_passing    0.000126\n",
      "5                         height_cm    0.000112\n",
      "34                 movement_balance    0.000094\n",
      "6                         weight_kg    0.000077\n",
      "8                club_jersey_number    0.000073\n",
      "42            mentality_positioning    0.000069\n",
      "36                    power_jumping    0.000056\n",
      "51              goalkeeping_kicking    0.000052\n",
      "26                      skill_curve    0.000047\n",
      "32                 movement_agility    0.000042\n",
      "93            player_positions_2_RW    0.000040\n",
      "19                           physic    0.000032\n",
      "94           player_positions_2_RWB    0.000027\n",
      "11                      skill_moves    0.000024\n",
      "82            player_positions_2_CB    0.000015\n",
      "10                        weak_foot    0.000014\n",
      "85            player_positions_2_CM    0.000010\n",
      "102               work_rate_Low/Low    0.000009\n",
      "81           player_positions_2_CAM    0.000008\n",
      "90           player_positions_2_LWB    0.000007\n",
      "108              body_type_2_Normal    0.000006\n",
      "95            player_positions_2_ST    0.000004\n",
      "106         work_rate_Medium/Medium    0.000003\n",
      "83           player_positions_2_CDM    0.000003\n",
      "98              work_rate_High/High    0.000003\n",
      "86            player_positions_2_GK    0.000002\n",
      "107                body_type_2_Lean    0.000001\n",
      "104           work_rate_Medium/High    0.000000\n",
      "105            work_rate_Medium/Low    0.000000\n",
      "103            work_rate_Low/Medium    0.000000\n",
      "100           work_rate_High/Medium    0.000000\n",
      "109              body_type_2_Stocky    0.000000\n",
      "101              work_rate_Low/High    0.000000\n",
      "91            player_positions_2_RB    0.000000\n",
      "99               work_rate_High/Low    0.000000\n",
      "97             preferred_foot_Right    0.000000\n",
      "96              preferred_foot_Left    0.000000\n",
      "92            player_positions_2_RM    0.000000\n",
      "89            player_positions_2_LW    0.000000\n",
      "88            player_positions_2_LM    0.000000\n",
      "87            player_positions_2_LB    0.000000\n",
      "84            player_positions_2_CF    0.000000\n",
      "7                      league_level    0.000000\n",
      "0                      fifa_version    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Define Gradient Boosting model\n",
    "gradient_boosting = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of boosting stages\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for splits\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gradient_boosting, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "# To check on the importance of each of the features\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", importance_df.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGBM model\n",
    "lgbm_model = LGBMRegressor(random_state=42, verbose=-1)\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of boosting stages\n",
    "    'learning_rate': [0.2, 0.3, 0.4],  # Learning rate\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
    "    'num_leaves': [31, 50, 75],  # Maximum number of leaves in one tree\n",
    "    'min_child_samples': [20, 50, 100],  # Minimum number of data needed in a child (leaf)\n",
    "    'subsample': [0.8, 0.9, 1.0],  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],  # Subsample ratio of columns when constructing each tree\n",
    "    'reg_alpha': [0, 0.1, 0.5],  # L1 regularization term on weights\n",
    "    'reg_lambda': [0, 0.1, 0.5]  # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=2, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "# Feature Importance (optional)\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", importance_df.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with L1/L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_py = df.drop(columns=['value_eur'] + exclude_columns).values  # Convert DataFrame to NumPy array\n",
    "y_py = df['value_eur'].values  # Convert Series to NumPy array\n",
    "\n",
    "# Split data into train and test based on 'fifa_version'\n",
    "X_train_py = X_py[df['fifa_version'] == 22]\n",
    "X_test_py = X_py[df['fifa_version'] == 23]\n",
    "y_train_py = y_py[df['fifa_version'] == 22]\n",
    "y_test_py = y_py[df['fifa_version'] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_py, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_py, dtype=torch.float32) \n",
    "X_test_tensor = torch.tensor(X_test_py, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_py, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, l1_value, l2_value):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, 1)\n",
    "        self.l1_value = l1_value\n",
    "        self.l2_value = l2_value\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x)) # to apply the ReLU function to the first hidden layer\n",
    "        x = torch.relu(self.fc2(x)) # to apply the ReLU function to the second hidden layer\n",
    "        x = torch.relu(self.fc3(x)) # to apply the ReLU function to the third hidden layer\n",
    "        x = torch.relu(self.fc4(x)) # to apply the ReLU function to the fourth layer\n",
    "        x = self.fc5(x) # output layer no activation function required\n",
    "        return x\n",
    "\n",
    "    def l1_l2_regularization(self):\n",
    "        l1_loss = sum(param.abs().sum() for param in self.parameters())\n",
    "        l2_loss = sum(param.pow(2.0).sum() for param in self.parameters())\n",
    "        return self.l1_value * l1_loss + self.l2_value * l2_loss\n",
    "\n",
    "# Wrap the PyTorch model in a scikit-learn compatible regressor\n",
    "net = NeuralNetRegressor(\n",
    "    module=NeuralNet,\n",
    "    module__input_size=X_train_tensor.shape[1],\n",
    "    module__hidden_size1=512,\n",
    "    module__hidden_size2=256,\n",
    "    module__hidden_size3=128,\n",
    "    module__hidden_size4=64,\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    max_epochs=300,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'module__l1_value': [0.2, 0.01],  # L1 regularization strength\n",
    "    'module__l2_value': [0.0, 0.15],  # L2 regularization strength\n",
    "    'max_epochs': [400],  # Number of epochs\n",
    "    'batch_size': [64,128]  # Batch size\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=net, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_tensor.numpy(), y_train_tensor.numpy().ravel())  # To flatten y \n",
    "\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_tensor.numpy())\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(y_test_py, y_pred)\n",
    "mse = mean_squared_error(y_test_py, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_py, y_pred)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_py, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we ran various ML algorithms and compared results we can take the last steps in our data pipeline. We choose the results from the best performing algorithm (or the one of our preference) and we take the final steps so that data is interpretable and ready to use for Tableau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best approach is to reload the original dataset, perform the changes and adhere the predicted column\n",
    "df2 = pd.read_csv(\"C:/Users/aleja/OneDrive/Desktop/Data Analytics Msc/Thesis/male_players.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat some of the data preprocessing steps so that the dataset is ready to be used with Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_operation(x):\n",
    "    x = str(x)  \n",
    "    if '+' in x:\n",
    "        return sum(map(int, x.split('+')))\n",
    "    elif '-' in x:\n",
    "        parts = x.split('-')\n",
    "        return int(parts[0]) - int(parts[1])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "# Apply the function to multiple columns\n",
    "columns_to_process = ['ls', 'st', 'rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk']          \n",
    "\n",
    "for col in columns_to_process:\n",
    "    if col in df2.columns:  \n",
    "        df2[col] = df2[col].apply(calculate_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna(subset=['value_eur'])\n",
    "df2 = df2.dropna(subset=['club_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pace'].fillna(df2['pace'].mean(), inplace=True)\n",
    "df2['shooting'].fillna(df2['shooting'].mean(), inplace=True)\n",
    "df2['passing'].fillna(df2['passing'].mean(), inplace=True)\n",
    "df2['dribbling'].fillna(df2['dribbling'].mean(), inplace=True)\n",
    "df2['mentality_composure'].fillna(df2['mentality_composure'].mean(), inplace=True)\n",
    "\n",
    "df2['defending'].fillna(df2['defending'].median(), inplace=True)\n",
    "df2['physic'].fillna(df2['physic'].median(), inplace=True)\n",
    "df2['release_clause_eur'].fillna(df2['release_clause_eur'].median(), inplace=True)\n",
    "\n",
    "df2['league_level'] = df2['league_level'].fillna(df2['league_level'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reverse the application of the Robust Scaler so that our target variable is comparable to original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "columns_to_scale = ['value_eur']\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# Access the median and IQR values used during scaling\n",
    "median = scaler.center_  # Median values for each column\n",
    "IQR = scaler.scale_      # IQR values for each column\n",
    "\n",
    "# Reverse the scaling\n",
    "original_data = scaled_data * IQR + median\n",
    "\n",
    "df['Market_Value_Rev'] = original_data  # Add the predicted market values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reverse the application of the log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Predicted_Market_Value'] = np.expm1(df['Market_Value_Rev'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we aperform a calculation to show the difference between the predicted value and the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Difference'] = df2['Predicted_Market_Value'] - df2['value_eur']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish by exporting our results into the data file of our choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df2.to_csv('Player_value_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
